{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet50 for six logo class of Trademark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "mount_file_id": "1islMlJ4NH_YIyVYiEblfKg2WLeuCIATU",
      "authorship_tag": "ABX9TyNHEV/O40dlQIo9To4ciXfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaxrays21/Resnet-50fortrademark/blob/main/Resnet50_for_six_logo_class_of_Trademark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbDPaOvmbucK",
        "outputId": "c11903d9-491f-4f32-b310-a9978607fff5"
      },
      "source": [
        "#!git clone https://github.com/Adithia88/Image-Classification-using-VGG19-and-Resnet"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Image-Classification-using-VGG19-and-Resnet'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 127 (delta 1), reused 0 (delta 0), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (127/127), 30.54 MiB | 9.08 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm5lT0eXkxT8",
        "outputId": "c1da740a-48bf-40a1-88eb-d7af2141bddc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import itertools\n",
        "import keras\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
        "from keras.models import Sequential \n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dropout, Flatten, Dense,AveragePooling2D\n",
        "from keras import applications  \n",
        "from keras.utils.np_utils import to_categorical  \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "import math  \n",
        "import datetime\n",
        "import time\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "print('Tensorflow_VER= V',tf.version.VERSION)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow_VER= V 2.4.1\n",
            "<function confusion_matrix at 0x7f6d5c68ca70>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODvzefrwlB1S"
      },
      "source": [
        "train_data_dir = '/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/train'  \n",
        "test_data_dir = '/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/test'\n",
        "validation_data_dir = '/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/val'  \n",
        "\n",
        "#TUNING SEBAGIAN DISINI\n",
        "batch_size = 16\n",
        "lr=1e-4\n",
        "opt='rmsprop'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3YO7iS8cD_k",
        "outputId": "fdcec962-acec-4005-be06-f260c5408130"
      },
      "source": [
        "#Feature Extraction cuy\n",
        "img_width, img_height = 224, 224  \n",
        "   \n",
        "top_model_weights_path = '/content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_fc_model.h5' \n",
        "\n",
        "epochs = 100 \n",
        "  \n",
        "\n",
        "resnet50 = applications.ResNet50(include_top=False, weights='imagenet') \n",
        "resnet50.summary() #Arsitekturnya Wan\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)  \n",
        "train_datagen = ImageDataGenerator(#rescale=1. / 255) \n",
        "        rescale=1. / 255,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)    \n",
        "#\n",
        "\n",
        "#Pre train Training\n",
        "start = datetime.datetime.now()\n",
        "   \n",
        "train_generator = train_datagen.flow_from_directory(  \n",
        "      train_data_dir,  \n",
        "      target_size=(img_width, img_height),  \n",
        "      batch_size=batch_size,  \n",
        "      class_mode=None,  \n",
        "      shuffle=False)  \n",
        "   \n",
        "nb_train_samples = len(train_generator.filenames)  \n",
        "num_classes = len(train_generator.class_indices)  \n",
        "   \n",
        "predict_size_train = int(math.ceil(nb_train_samples / batch_size))  \n",
        "   \n",
        "bottleneck_features_train = resnet50.predict_generator(train_generator, predict_size_train)  \n",
        "   \n",
        "np.save('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_train.npy', bottleneck_features_train)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "Found 4703 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time:  0:01:26.778533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68c27udAce3X",
        "outputId": "32372bed-2f0d-4a1d-d366-76abcc501c57"
      },
      "source": [
        "#Pre-train Validation cuy\n",
        "start = datetime.datetime.now()\n",
        "generator = datagen.flow_from_directory(  \n",
        "      validation_data_dir,  \n",
        "      target_size=(img_width, img_height),  \n",
        "      batch_size=batch_size,  \n",
        "      class_mode=None,  \n",
        "      shuffle=False)  \n",
        "   \n",
        "nb_validation_samples = len(generator.filenames)  \n",
        "num_classes = len(generator.class_indices)  \n",
        "\n",
        "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
        "   \n",
        "bottleneck_features_validation = resnet50.predict_generator(  \n",
        "      generator, predict_size_validation)  \n",
        "   \n",
        "np.save('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_validation.npy', bottleneck_features_validation) \n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time:  0:00:00.836182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP4bkANXdBmh",
        "outputId": "695f5cf7-47f4-4b49-c6a1-bfe0346372e2"
      },
      "source": [
        "#Pre train Testing\n",
        "start = datetime.datetime.now()\n",
        "generator = datagen.flow_from_directory(  \n",
        "      test_data_dir,  \n",
        "      target_size=(img_width, img_height),  \n",
        "      batch_size=batch_size,  \n",
        "      class_mode=None,  \n",
        "      shuffle=False)  \n",
        "   \n",
        "nb_test_samples = len(generator.filenames)  \n",
        "   \n",
        "predict_size_test = int(math.ceil(nb_test_samples / batch_size))  \n",
        "   \n",
        "bottleneck_features_test = resnet50.predict_generator(  \n",
        "      generator, predict_size_test)  \n",
        "   \n",
        "np.save('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_test.npy', bottleneck_features_test) \n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time:  0:01:42.449826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbn7rlJBlWSL",
        "outputId": "1578ffe3-40a6-4b9b-8e0b-49529e37dff1"
      },
      "source": [
        "\"\"\"#Feature Extraction cuy\n",
        "img_width, img_height = 224, 224  \n",
        "   \n",
        "top_model_weights_path = '/content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_fc_model.h5' \n",
        "\n",
        "epochs = 100 \n",
        "  \n",
        "\n",
        "resnet50 = applications.ResNet50(include_top=False, weights='imagenet') \n",
        "resnet50.summary() #Arsitekturnya Wan\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)  \n",
        "train_datagen = ImageDataGenerator(#rescale=1. / 255) \n",
        "        rescale=1. / 255,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)    \n",
        "#\n",
        "\n",
        "#Pre train Training\n",
        "start = datetime.datetime.now()\n",
        "   \n",
        "train_generator = train_datagen.flow_from_directory(  \n",
        "      train_data_dir,  \n",
        "      target_size=(img_width, img_height),  \n",
        "      batch_size=batch_size,  \n",
        "      class_mode=None,  \n",
        "      shuffle=False)  \n",
        "   \n",
        "nb_train_samples = len(train_generator.filenames)  \n",
        "num_classes = len(train_generator.class_indices)  \n",
        "   \n",
        "predict_size_train = int(math.ceil(nb_train_samples / batch_size))  \n",
        "   \n",
        "bottleneck_features_train = resnet50.predict_generator(train_generator, predict_size_train)  \n",
        "   \n",
        "np.save('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_train.npy', bottleneck_features_train)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n",
        "\n",
        "#Pre-train Validation cuy\n",
        "start = datetime.datetime.now()\n",
        "generator = datagen.flow_from_directory(  \n",
        "      validation_data_dir,  \n",
        "      target_size=(img_width, img_height),  \n",
        "      batch_size=batch_size,  \n",
        "      class_mode=None,  \n",
        "      shuffle=False)  \n",
        "   \n",
        "nb_validation_samples = len(generator.filenames)  \n",
        "num_classes = len(generator.class_indices)  \n",
        "\n",
        "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
        "   \n",
        "bottleneck_features_validation = resnet50.predict_generator(  \n",
        "      generator, predict_size_validation)  \n",
        "   \n",
        "np.save('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_validation.npy', bottleneck_features_validation) \n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n",
        "\n",
        "#Pre train Testing\n",
        "start = datetime.datetime.now()\n",
        "generator = datagen.flow_from_directory(  \n",
        "      test_data_dir,  \n",
        "      target_size=(img_width, img_height),  \n",
        "      batch_size=batch_size,  \n",
        "      class_mode=None,  \n",
        "      shuffle=False)  \n",
        "   \n",
        "nb_test_samples = len(generator.filenames)  \n",
        "   \n",
        "predict_size_test = int(math.ceil(nb_test_samples / batch_size))  \n",
        "   \n",
        "bottleneck_features_test = resnet50.predict_generator(  \n",
        "      generator, predict_size_test)  \n",
        "   \n",
        "np.save('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_test.npy', bottleneck_features_test) \n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "Found 4703 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4e66f91a63d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mpredict_size_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_train_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mbottleneck_features_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_size_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_features_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m   \u001b[0;31m######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VnASJ-qJp8Vl",
        "outputId": "316302c2-a3ad-4c78-eb7a-8d4cf8894d72"
      },
      "source": [
        "#TRAINING dan Testing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#TRAINING\n",
        "#hasil= []\n",
        "#resnet50 = applications.resnet50(include_top=False, weights='imagenet') \n",
        "def read_image(file_path):\n",
        "    print(\"[INFO] loading and preprocessing image...\")  \n",
        "    image = load_img(file_path, target_size=(224, 224))  \n",
        "    image = img_to_array(image)  \n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image /= 255.  \n",
        "    return image\n",
        "\n",
        "#To get better visual of the confusion matrix:\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "             normalize=False,\n",
        "             title='Confusion matrix',\n",
        "             cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"confusion matrix yang dinormalisasi \\n\\n\\n\")\n",
        "    else:\n",
        "        print('Confusion matrix tanpa normalisasi \\n\\n\\n')\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "img_width, img_height = 224, 224  \n",
        "top_model_weights_path = 'bottleneck_fc_model.h5' \n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1. / 255) \n",
        " \n",
        "#training data\n",
        "generator_top = datagen.flow_from_directory(  \n",
        "         train_data_dir,  \n",
        "         target_size=(img_width, img_height),  \n",
        "         batch_size=batch_size,  \n",
        "         class_mode='categorical',  \n",
        "         shuffle=False)  \n",
        "   \n",
        "nb_train_samples = len(generator_top.filenames)  \n",
        "num_classes = len(generator_top.class_indices)  \n",
        "   \n",
        "train_data = np.load('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_train.npy')  \n",
        "\n",
        "train_labels = generator_top.classes  \n",
        "   \n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes) \n",
        "\n",
        "#testing data\n",
        "generator_top = datagen.flow_from_directory(  \n",
        "         test_data_dir,  \n",
        "         target_size=(img_width, img_height),  \n",
        "         batch_size=batch_size,  \n",
        "         class_mode=None,  \n",
        "         shuffle=False)  \n",
        "   \n",
        "nb_test_samples = len(generator_top.filenames)  \n",
        "   \n",
        "test_data = np.load('/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/bottleneck_features_test.npy')  \n",
        "   \n",
        "\n",
        "test_labels = generator_top.classes  \n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "#Lanjut training \n",
        "start = datetime.datetime.now()\n",
        "model = Sequential()\n",
        "#model.add(AveragePooling2D(pool_size=(7, 7)))\n",
        "model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
        "model.add(Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=lr),\n",
        "              metrics=['acc'])  \n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "mc = ModelCheckpoint('/content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "# history = model.fit(train_data, train_labels,  \n",
        "#       epochs=20,\n",
        "#       batch_size=batch_size,  \n",
        "#       validation_data=(test_data, test_labels))\n",
        "\n",
        "\n",
        "history = model.fit(train_data, train_labels,  \n",
        "      epochs=100,\n",
        "      batch_size=batch_size,  \n",
        "      validation_data=(test_data, test_labels),\n",
        "      verbose=0,\n",
        "      callbacks=[es, mc])    \n",
        "\n",
        "model.save_weights(top_model_weights_path)  \n",
        "\n",
        "(eval_loss, eval_accuracy) = model.evaluate(  \n",
        " test_data, test_labels, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))  \n",
        "print(\"[INFO] Loss: {}\".format(eval_loss))  \n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ('Time: ', elapsed)\n",
        "\n",
        "#Model summary\n",
        "model.summary()\n",
        "\n",
        "#Graphing our training and validation\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plotacc = plt.figure(1)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plotacc.show()\n",
        "plt.savefig(\"/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/gambar/resnet50/train/Acc_resnet50_{}Batch_{}E_Opt={}_lr={}.jpg\".format(batch_size, len(acc),opt,lr))\n",
        "\n",
        "\n",
        "\n",
        "plotloss = plt.figure(2)\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plotloss.show()\n",
        "plt.savefig(\"/content/drive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/gambar/resnet50/train/Loss_resnet50_{}Batch_{}E_Opt={}_lr={}.jpg\".format(batch_size, len(acc),opt,lr))\n",
        "\n",
        "Evaluasi=model.evaluate(test_data, test_labels)\n",
        "print(Evaluasi)\n",
        "\n",
        "\n",
        "print('test data', test_data)\n",
        "preds = np.round(model.predict(test_data),0) \n",
        "score = model.predict(test_data)\n",
        "#to fit them into classification metrics and confusion metrics, some additional modificaitions are required\n",
        "print('rounded test_labels', preds)\n",
        "#Model di save \n",
        "model.save('/content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/models/resnet50/model_{}E.h5'.format(len(acc)))\n",
        "\n",
        "view = ['Logo0','Logo1','Logo2','Logo3','Logo4','Logo5']\n",
        "classification_metrics = metrics.classification_report(test_labels, preds, target_names=view )\n",
        "print(classification_metrics)\n",
        "\n",
        "#Since our data is in dummy format we put the numpy array into a dataframe and call idxmax axis=1 to return the column\n",
        "# label of the maximum value thus creating a categorical variable\n",
        "#Basically, flipping a dummy variable back to it's categorical variable\n",
        "categorical_test_labels = pd.DataFrame(test_labels).idxmax(axis=1)\n",
        "categorical_preds = pd.DataFrame(preds).idxmax(axis=1)\n",
        "confusion_matrix= confusion_matrix(categorical_test_labels, categorical_preds)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4703 images belonging to 6 classes.\n",
            "Found 120 images belonging to 6 classes.\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.84167, saving model to /content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/best_model.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.84167 to 0.97500, saving model to /content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/best_model.h5\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.97500\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.97500\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.97500\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.97500 to 0.98333, saving model to /content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/best_model.h5\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.98333\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.98333\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.98333\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.98333 to 1.00000, saving model to /content/gdrive/MyDrive/Dataset/Dataset for first keras/temp3 set of 20/best_model.h5\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 1.00000\n",
            "Epoch 00031: early stopping\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.0048 - acc: 1.0000\n",
            "[INFO] accuracy: 100.00%\n",
            "[INFO] Loss: 0.004780965857207775\n",
            "Time:  0:00:38.661909\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 602118    \n",
            "=================================================================\n",
            "Total params: 602,118\n",
            "Trainable params: 602,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0048 - acc: 1.0000\n",
            "[0.004780965857207775, 1.0]\n",
            "test data [[[[ 0.          0.          0.         ...  2.1543128   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.4886674   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.5617445   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.81081486 ...  1.9842575   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.4479744   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.1555665   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.5302868   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.008569    0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  3.4639952   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.32372     0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.5649147   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.036531    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  6.315262    0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  8.100389    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.211463    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.8987904   0.\n",
            "     0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.0992887   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.6519067   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  4.9016795   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.02907873  0.         ...  7.794843    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  6.794497    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.9668938   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.6695899   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.7985493   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  5.8845577   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.4215322   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.1652677   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.9607246   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  2.9352336   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.4076953   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  4.735455    0.\n",
            "     0.        ]]]\n",
            "\n",
            "\n",
            " [[[ 0.          0.          0.         ...  2.0681908   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.8852159   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.7030064  ...  2.0682044   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          1.1803638  ...  1.7341464   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.1448219   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.1929307   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.2192512   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.3817537   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  3.9791727   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.033406    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.30942094  0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.38193953  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.5516831   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.78784     0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  7.819452    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.2991495   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.7690067   0.\n",
            "     0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.30027187  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.1798942   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.5462005   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.2145409   0.         ...  7.037982    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.1935673   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.6232666   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.381106    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.265738    0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  4.768134    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.6933608   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.2135112   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.553946    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  1.5185727   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.9643133   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.8730495   0.\n",
            "     0.        ]]]\n",
            "\n",
            "\n",
            " [[[ 0.          0.          0.         ...  2.1843672   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.0773937   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.752387    0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.99882054 ...  2.1387534   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.1956167   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.3732705   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.0939393   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.7308984   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  4.486395    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.7595563   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.72027445  0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.2427492   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.3113294   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  7.7213984   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.9644277   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.2205067   0.\n",
            "     0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.8920901   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.2852287   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.15968248  0.         ...  3.1503954   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  4.8663387   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.4339337   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.7753792   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.0067945   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.6402144   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  4.1482553   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.7533333   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.3776363   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.11775112  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.95587397  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  4.277261    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.6925633   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.6211913   0.\n",
            "     0.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.          0.          0.         ...  2.119505    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.6859447   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.2022381   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.01469243 ...  1.774072    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.5791938   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.028707    0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.6662865   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.5473018   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  1.4946451   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.2295136   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.6595957   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.9601524   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  4.0276036   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.98061     0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  3.7570903   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.1627405   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  4.617177    0.\n",
            "     0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.          0.          0.         ...  4.1522737   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  6.9403768   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  8.986297    0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  8.511599    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ... 10.148399    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  4.569679    0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  1.6423273   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.5652795   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.532828    0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  7.4207506   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  8.9728      0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.658003    0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  2.4333258   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  6.070265    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.1324677   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  6.2909007   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  7.033555    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.514345    0.\n",
            "     0.        ]]]\n",
            "\n",
            "\n",
            " [[[ 0.          0.          0.         ...  1.9320277   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.3687894   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.67087936 ...  1.7978914   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          1.3391085  ...  3.424707    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.120441    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.995837    0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.9439503   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.5261052   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  3.397926    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.9400418   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.35102105  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.9856384   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  2.769644    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.5035617   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.7061336   0.\n",
            "     0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.0203843   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.0029337   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  3.1358666   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  5.165146    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.8657688   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.5957952   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.158779    0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  2.138719    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.7224226   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.89630604  0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.5316067   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.2135768   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.5328336   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  2.0286496   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.33528495  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.5550699   0.\n",
            "     0.        ]]]\n",
            "\n",
            "\n",
            " [[[ 0.          0.          0.         ...  2.5803165   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.2378948   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.9053086  ...  1.0747174   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          2.0003934  ...  2.1424541   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.08821809 ...  1.5708021   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.1330304   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.46177948  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.9580199   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.8771217   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  2.5449166   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.0869079   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.48389065  0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  1.4381506   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.095255    0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  4.0598555   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  3.9615085   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.6059897   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.0373702   0.\n",
            "     0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.3817713   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.9008398   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  3.0097268   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.2862839   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.2618675   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.          0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.9255263   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.4041667   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  1.1270176   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  0.5286256   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.6081349   0.\n",
            "     0.        ]]\n",
            "\n",
            "  [[ 0.          0.          0.         ...  0.27806032  0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.8027043   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  1.6626068   0.\n",
            "     0.        ]\n",
            "   ...\n",
            "   [ 0.          0.          0.         ...  2.9824028   0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  2.95827     0.\n",
            "     0.        ]\n",
            "   [ 0.          0.          0.         ...  3.9048114   0.\n",
            "     0.        ]]]]\n",
            "rounded test_labels [[1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Logo0       1.00      1.00      1.00        20\n",
            "       Logo1       1.00      1.00      1.00        20\n",
            "       Logo2       1.00      1.00      1.00        20\n",
            "       Logo3       1.00      1.00      1.00        20\n",
            "       Logo4       1.00      1.00      1.00        20\n",
            "       Logo5       1.00      1.00      1.00        20\n",
            "\n",
            "   micro avg       1.00      1.00      1.00       120\n",
            "   macro avg       1.00      1.00      1.00       120\n",
            "weighted avg       1.00      1.00      1.00       120\n",
            " samples avg       1.00      1.00      1.00       120\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "ANnZPKhTrb2s",
        "outputId": "4be5b2c8-a46c-41d1-e4e8-18c149675cdc"
      },
      "source": [
        "plotcmnn = plt.figure(3)    \n",
        "plot_confusion_matrix(confusion_matrix, ['Logo0','Logo1','Logo2','Logo3','Logo4','Logo5'])  \n",
        "plt.savefig(\"/content/Image-Classification-using-VGG19-and-Resnet/gambar/resnet50/train/CMNN_resnet50_{}Batch_{}E_Opt={}_lr={}.jpg\".format(batch_size, len(acc),opt,lr))\n",
        "\n",
        "plotcmn = plt.figure(4) \n",
        "plot_confusion_matrix(confusion_matrix, ['Logo0','Logo1','Logo2','Logo3','Logo4','Logo5'],normalize=True)\n",
        "plt.savefig(\"/content/Image-Classification-using-VGG19-and-Resnet/gambar/resnet50/train/CMN_resnet50_{}Batch_{}E_Opt={}_lr={}.jpg\".format(batch_size, len(acc),opt,lr))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix tanpa normalisasi \n",
            "\n",
            "\n",
            "\n",
            "confusion matrix yang dinormalisasi \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}